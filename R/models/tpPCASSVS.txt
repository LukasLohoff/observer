model{
  ## hierarchically pooled data model variance
  for(j in 1:t){
    tau_inv[j] ~ dlnorm(mu_tau, tau2_tau)              # pooling prior for data model sqrt(precision)
    tau2[j] <- pow(tau_inv[j], -2)                     # data model precision
  }
  mu_tau ~ dnorm(0, 1 / 100)                           # pooled mean for data model sqrt(precision)
  tau_tau ~ dunif(0, 100)                              # pooled sqrt(precision) for data model sqrt(precision)
  tau2_tau <- pow(tau_tau, 2)                          # pooled precision for data model sqrt(precision)
  ## latent variance model 
  s_inv ~ dunif(0, 100)                                # prior for latent principal component sqrt(precision)
  s2 <- pow(s_inv, -2)                                 # prior for latent principal component precision
  M_inv <- inverse(tKK / s2 + I_p)                     # scaling matrix for PCA

  for (i in 1:N_total){
    mu_y[i] <- X[H[i], ] %*% K_hat %*% M_inv %*% beta[, tt[i]] / s2
                                                      # data model mean for sparse data format
                                                      # X <- original data matrix
                                                      # K_hat <- PCA rotation matrix
                                                      # H <- observation indicator
    ## hierarchically pooled degress of freedom
    v_inv[i] ~ dchisq(nu[tt[i]])                      # scale mixture for t data model variance 
    v[i] <- (nu[tt[i]] * tau2[tt[i]]) / v_inv[i]      # transformation to scaled inv-Chi squared variance
    tau_y[i] <- pow(v[i] + t(beta[, tt[i]]) %*% M_inv %*% beta[, tt[i]], -1)
                                                      # data model precision for sparse data format
  }

  # hierarchically pooled ssvs priors
  for(i in 1:t){
    tau_beta[i] ~ dlnorm(mu_tau_beta, tau2_tau_beta)   # regression coefficient sqrt(precision)
    tau2_beta[i] <- pow(tau_beta[i], 2)                # regression coefficient precision
    precision_beta[1, i] <- tau2_beta[i]               # regression coefficient effectively zero
    precision_beta[2, i] <- tau2_beta[i] / 1000        # nonzero coefficient
  }
  mu_tau_beta ~ dnorm(0, 1 / 100)                      # pooled mean for regression coefficient sqrt(precision)
  tau_tau_beta ~ dunif(0, 100)                         # pooled sqrt(precision) for regression coefficient sqrt(precision)
  tau2_tau_beta <- pow(tau_tau_beta, 2)                # pooled precision for  regression coefficient sqrt(precision)
  p_ind[1] <- 1/2                                      # prior probability of nonzero coefficient
  p_ind[2] <- 1 - p_ind[1]                             # prior probability effectively zero coefficient

  for (j in 1:t){
    for(i in 1:p){
      indA[i, j] ~ dcat(p_ind[])                       # sample indicator for nonzero coefficient, returns 1 or 2 
      gamma[i, j] <- indA[i, j] - 1                    # transform indicator from 0-1 to 1-2 for indexing, returns 0 or 1
      beta[i, j] ~ dnorm(0, precision_beta[indA[i, j], j])  # ssvs prior for regression coefficients
    }
  }
  
  # t degrees of freedom
  for(i in 1:t){

    nu_inv[i] ~ dbeta(alpha_nu, beta_nu)               # pooled inverse degrees of freedom for t data model
    nu[i] <- 2 / nu_inv[i]                             # pooled degrees of freedom for t data model
    # nu[i] ~ dgamma(2, 0.1)                             # unpooled degrees of freedom for t data model
  }
  # mu_nu ~ dbeta(0.5, 0.5)                              # prior for alternative parameterization
  mu_nu ~ dbeta(2, 2)                              # prior for alternative parameterization
  eta_nu ~ dgamma(1, 1)                                # prior for alternative parameterization
  alpha_nu <- mu_nu * eta_nu                           # transformation of prior
  beta_nu <- (1 - mu_nu) * eta_nu                      # transformation of prior

  # likelihood
  for (i in 1:N_total){
    Y[i] ~ dnorm(mu_y[i], tau_y[i])                    # t mixture data model using precision
    log_like[i] <- dnorm(Y[i], mu_y[i], tau_y[i])      # t mixture data likelihood using precision 
  }
}
