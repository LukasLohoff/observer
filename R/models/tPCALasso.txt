model{
  ## hierarchically pooled data model sqrt(precision)
  for(i in 1:t){
    s_inv[i] ~ dlnorm(mu_s_inv, tau2_s)                # pooling prior for data model sqrt(precision)
    s2[i] <- pow(s_inv[i], -2)                         # data model precision
  }
  mu_s_inv ~ dnorm(0, 1 / 100)                         # pooled mean for data model sqrt(precision)
  tau_s ~ dunif(0, 100)                                # pooled sqrt(precision) for data model sqrt(precision)
  tau2_s <- pow(tau_s, 2)                              # pooled precision for data model sqrt(precision)

  for (i in 1:N_total){
    mu_y[i] <- X[H[i], ] %*% beta[, tt[i]]             # data model mean for sparse data format
                                                       # X <- PCA rotation matrix
                                                       # H <- observation indicator
    ## hierarchically pooled degress of freedom
    v_inv[i] ~ dchisq(nu[tt[i]])                       # scale mixture for t data model variance 
    v[i] <- (nu[tt[i]] * s2[tt[i]]) / v_inv[i]         # transformation to scaled inv-Chi squared variance
  }

  # lasso priors
  for(j in 1:t){  
    lambda2[j] ~ dgamma(alpha_lambda2, beta_lambda2)  # hierarchically pooled lasso shrinkage parameter
    for(i in 1:p){
      gamma2[i, j] ~ dexp(lambda2[j] / 2)             # lasso scale mixture parameter
      beta[i, j] ~ dnorm(0, 1 / (s2[j] * nu[j] / (nu[j] - 2) * gamma2[i, j] * D[i]))  # lasso prior model for tPCA 
                                                      # D is a vector of singular values from PCA
    }
  }
  mu_lambda2 ~ dlnorm(0, 1 / 100)                       # hierarchical mean of lambda2 gamma distribution
  s_lambda2 ~ dunif(0, 100)                            # hierarchical standard deviation of lambda2 gamma distribution
  alpha_lambda2 <- pow(mu_lambda2, 2) / pow(s_lambda2, 2) # reparameterization of gamma distribution
  beta_lambda2 <- mu_lambda2 / pow(s_lambda2, 2)       # reparameterization of gamma distribution

  # t degrees of freedom
  for(i in 1:t){
    nu_inv[i] ~ dbeta(alpha_nu, beta_nu)               # pooled inverse degrees of freedom for t data model
    nu[i] <- 2 / nu_inv[i]                             # pooled degrees of freedom for t data model
  }
  # mu_nu ~ dbeta(0.5, 0.5)                              # prior for alternative parameterization
  mu_nu ~ dbeta(2, 2)                              # prior for alternative parameterization
  eta_nu ~ dgamma(1, 1)                                # prior for alternative parameterization
  alpha_nu <- mu_nu * eta_nu                           # transformation of prior
  beta_nu <- (1 - mu_nu) * eta_nu                      # transformation of prior

  # likelihood
  for (i in 1:N_total){
    Y[i] ~ dnorm(mu_y[i], 1 / v[i])                    # t mixture data model using precision
    log_like[i] <- dnorm(Y[i], mu_y[i], 1 / v[i])      # t mixture data likelihood using precision
  }

}
